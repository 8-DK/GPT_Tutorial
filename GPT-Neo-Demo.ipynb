{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd1215a",
   "metadata": {},
   "source": [
    "# GPT Neo 1.3B Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e83f1",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/8-DK\" ><img width=70px src=\"https://avatars.githubusercontent.com/u/16573799?v=4\" alt=\"8-Dk\" title=\"Logo\" /></a>\n",
    "Author : <b>Dhananjay Khairnar</b><br>\n",
    "Git : <b><a href=\"https://github.com/8-DK\" >https://github.com/8-DK</a></b><br>\n",
    "LinkedIn : <b><a href=\"https://www.linkedin.com/in/khairnardm/\" >https://www.linkedin.com/in/khairnardm/</a></b></br>\n",
    "YouTube : <b><a href=\"https://www.youtube.com/channel/UC5NBBz7RSbfOPFVDna5MI-A\" >https://www.youtube.com/channel/UC5NBBz7RSbfOPFVDna5MI-A</a></b><br>\n",
    "Date : <b>28/02/2023</b><br>\n",
    "Country : <b>India</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe56987",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%js\n",
    "window.open('https://www.youtube.com/channel/UC5NBBz7RSbfOPFVDna5MI-A', '_blank');\n",
    "//Visite my YouTube channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60a78f",
   "metadata": {},
   "source": [
    "<b>1. Install require python library</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df295e",
   "metadata": {},
   "source": [
    "Before starting notebook run following commands one time<br>\n",
    "- Create virtual enviornmet<br>\n",
    "\tconda create -n gpt<br>\n",
    "<br>\n",
    "- Install cudatoolkit and cudnn<br>\n",
    "\tconda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0<br>\n",
    "<br>\n",
    "- Install tensorflow if we want run tf model<br>\n",
    "\tpython -m pip install tensorflow==2.5.0<br>\n",
    "<br>\n",
    "- Install pytorch with cuda support<br>\n",
    "\tconda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch<br>\n",
    "<br>\n",
    "- Install Jupyter Note book<br>\n",
    "\tpip install jupyter<br>\n",
    "<br>\n",
    "- Install required numpy library<br>\n",
    "\tpip uninstall numpy<br>\n",
    "\tpip install numpy==1.21<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d5224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall numpy #commend after running first time\n",
    "!pip install numpy==1.21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5493d5c6",
   "metadata": {},
   "source": [
    "<b>2. Import python library</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from datetime import datetime\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac55c5f",
   "metadata": {},
   "source": [
    "<b>3. Load model.</b><br> if model not available in cache then it will be downloaded from server. size of model is aprox 5.5G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c38763",
   "metadata": {},
   "source": [
    "<b>4. Create prompt input ro model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =\"who is Narendra modi?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a70be",
   "metadata": {},
   "source": [
    "<b>5. Tokenize input string</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3857e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead61a4a",
   "metadata": {},
   "source": [
    "<b>6. Generate output in form of tokenize data</b><br>\n",
    "here max_length is length of output data, try to increase it for long text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = datetime.now()\n",
    "gen_tokens = model.generate(input_ids,do_sample=True,temperature=0.7,max_length=200,)\n",
    "t2 = datetime.now()\n",
    "\n",
    "# get difference\n",
    "delta = t2 - t1\n",
    "\n",
    "# Time taken to generate\n",
    "print(f\"Time taken is {delta} , {delta.total_seconds()} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c55ae9",
   "metadata": {},
   "source": [
    "<b>7. Decode tokinize data into string</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaf85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9defe43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
